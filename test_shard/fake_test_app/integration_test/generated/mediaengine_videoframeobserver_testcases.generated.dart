/// GENERATED BY testcase_gen. DO NOT MODIFY BY HAND.

// ignore_for_file: deprecated_member_use,constant_identifier_names

import 'dart:async';
import 'dart:typed_data';

import 'package:agora_rtc_engine/agora_rtc_engine.dart';
import 'package:flutter/foundation.dart';
import 'package:flutter_test/flutter_test.dart';
import 'package:iris_tester/iris_tester.dart';
import 'package:iris_method_channel/iris_method_channel.dart';

import '../testcases/event_ids_mapping.dart';

void generatedTestCases(ValueGetter<IrisTester> irisTester) {
  testWidgets(
    'VideoFrameObserver.onCaptureVideoFrame',
    (WidgetTester tester) async {
      RtcEngine rtcEngine = createAgoraRtcEngine();
      await rtcEngine.initialize(RtcEngineContext(
        appId: 'app_id',
        areaCode: AreaCode.areaCodeGlob.value(),
      ));
      await rtcEngine.setParameters('{"rtc.enable_debug_log": true}');
      final mediaEngine = rtcEngine.getMediaEngine();

      final onCaptureVideoFrameCompleter = Completer<bool>();
      final theVideoFrameObserver = VideoFrameObserver(
        onCaptureVideoFrame:
            (VideoSourceType sourceType, VideoFrame videoFrame) {
          onCaptureVideoFrameCompleter.complete(true);
        },
      );

      mediaEngine.registerVideoFrameObserver(
        theVideoFrameObserver,
      );

// Delay 500 milliseconds to ensure the registerVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      {
        const VideoSourceType sourceType =
            VideoSourceType.videoSourceCameraPrimary;
        const VideoPixelFormat videoFrameType =
            VideoPixelFormat.videoPixelDefault;
        const VideoFrameMetaInfo? videoFrameMetaInfo = null;
        const int videoFrameWidth = 10;
        const int videoFrameHeight = 10;
        const int videoFrameYStride = 10;
        const int videoFrameUStride = 10;
        const int videoFrameVStride = 10;
        Uint8List videoFrameYBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameUBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameVBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameRotation = 10;
        const int videoFrameRenderTimeMs = 10;
        const int videoFrameAvsyncType = 10;
        Uint8List videoFrameMetadataBuffer =
            Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameMetadataSize = 10;
        const int videoFrameTextureId = 10;
        const List<double> videoFrameMatrix = [];
        Uint8List videoFrameAlphaBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFramePixelBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        final VideoFrame videoFrame = VideoFrame(
          type: videoFrameType,
          width: videoFrameWidth,
          height: videoFrameHeight,
          yStride: videoFrameYStride,
          uStride: videoFrameUStride,
          vStride: videoFrameVStride,
          yBuffer: videoFrameYBuffer,
          uBuffer: videoFrameUBuffer,
          vBuffer: videoFrameVBuffer,
          rotation: videoFrameRotation,
          renderTimeMs: videoFrameRenderTimeMs,
          avsyncType: videoFrameAvsyncType,
          metadataBuffer: videoFrameMetadataBuffer,
          metadataSize: videoFrameMetadataSize,
          textureId: videoFrameTextureId,
          matrix: videoFrameMatrix,
          alphaBuffer: videoFrameAlphaBuffer,
          pixelBuffer: videoFramePixelBuffer,
          metaInfo: videoFrameMetaInfo,
        );

        final eventJson = {
          'sourceType': sourceType.value(),
          'videoFrame': videoFrame.toJson(),
        };

        final eventIds =
            eventIdsMapping['VideoFrameObserver_onCaptureVideoFrame'] ?? [];
        for (final event in eventIds) {
          final ret = irisTester().fireEvent(event, params: eventJson);
          // Delay 200 milliseconds to ensure the callback is called.
          await Future.delayed(const Duration(milliseconds: 200));
          // TODO(littlegnal): Most of callbacks on web are not implemented, we're temporarily skip these callbacks at this time.
          if (kIsWeb && ret) {
            if (!onCaptureVideoFrameCompleter.isCompleted) {
              onCaptureVideoFrameCompleter.complete(true);
            }
          }
        }
      }

      final eventCalled = await onCaptureVideoFrameCompleter.future;
      expect(eventCalled, isTrue);

      {
        mediaEngine.unregisterVideoFrameObserver(
          theVideoFrameObserver,
        );
      }
// Delay 500 milliseconds to ensure the unregisterVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      await rtcEngine.release();
    },
    timeout: const Timeout(Duration(minutes: 2)),
  );

  testWidgets(
    'VideoFrameObserver.onPreEncodeVideoFrame',
    (WidgetTester tester) async {
      RtcEngine rtcEngine = createAgoraRtcEngine();
      await rtcEngine.initialize(RtcEngineContext(
        appId: 'app_id',
        areaCode: AreaCode.areaCodeGlob.value(),
      ));
      await rtcEngine.setParameters('{"rtc.enable_debug_log": true}');
      final mediaEngine = rtcEngine.getMediaEngine();

      final onPreEncodeVideoFrameCompleter = Completer<bool>();
      final theVideoFrameObserver = VideoFrameObserver(
        onPreEncodeVideoFrame:
            (VideoSourceType sourceType, VideoFrame videoFrame) {
          onPreEncodeVideoFrameCompleter.complete(true);
        },
      );

      mediaEngine.registerVideoFrameObserver(
        theVideoFrameObserver,
      );

// Delay 500 milliseconds to ensure the registerVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      {
        const VideoSourceType sourceType =
            VideoSourceType.videoSourceCameraPrimary;
        const VideoPixelFormat videoFrameType =
            VideoPixelFormat.videoPixelDefault;
        const VideoFrameMetaInfo? videoFrameMetaInfo = null;
        const int videoFrameWidth = 10;
        const int videoFrameHeight = 10;
        const int videoFrameYStride = 10;
        const int videoFrameUStride = 10;
        const int videoFrameVStride = 10;
        Uint8List videoFrameYBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameUBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameVBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameRotation = 10;
        const int videoFrameRenderTimeMs = 10;
        const int videoFrameAvsyncType = 10;
        Uint8List videoFrameMetadataBuffer =
            Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameMetadataSize = 10;
        const int videoFrameTextureId = 10;
        const List<double> videoFrameMatrix = [];
        Uint8List videoFrameAlphaBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFramePixelBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        final VideoFrame videoFrame = VideoFrame(
          type: videoFrameType,
          width: videoFrameWidth,
          height: videoFrameHeight,
          yStride: videoFrameYStride,
          uStride: videoFrameUStride,
          vStride: videoFrameVStride,
          yBuffer: videoFrameYBuffer,
          uBuffer: videoFrameUBuffer,
          vBuffer: videoFrameVBuffer,
          rotation: videoFrameRotation,
          renderTimeMs: videoFrameRenderTimeMs,
          avsyncType: videoFrameAvsyncType,
          metadataBuffer: videoFrameMetadataBuffer,
          metadataSize: videoFrameMetadataSize,
          textureId: videoFrameTextureId,
          matrix: videoFrameMatrix,
          alphaBuffer: videoFrameAlphaBuffer,
          pixelBuffer: videoFramePixelBuffer,
          metaInfo: videoFrameMetaInfo,
        );

        final eventJson = {
          'sourceType': sourceType.value(),
          'videoFrame': videoFrame.toJson(),
        };

        final eventIds =
            eventIdsMapping['VideoFrameObserver_onPreEncodeVideoFrame'] ?? [];
        for (final event in eventIds) {
          final ret = irisTester().fireEvent(event, params: eventJson);
          // Delay 200 milliseconds to ensure the callback is called.
          await Future.delayed(const Duration(milliseconds: 200));
          // TODO(littlegnal): Most of callbacks on web are not implemented, we're temporarily skip these callbacks at this time.
          if (kIsWeb && ret) {
            if (!onPreEncodeVideoFrameCompleter.isCompleted) {
              onPreEncodeVideoFrameCompleter.complete(true);
            }
          }
        }
      }

      final eventCalled = await onPreEncodeVideoFrameCompleter.future;
      expect(eventCalled, isTrue);

      {
        mediaEngine.unregisterVideoFrameObserver(
          theVideoFrameObserver,
        );
      }
// Delay 500 milliseconds to ensure the unregisterVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      await rtcEngine.release();
    },
    timeout: const Timeout(Duration(minutes: 2)),
  );

  testWidgets(
    'VideoFrameObserver.onMediaPlayerVideoFrame',
    (WidgetTester tester) async {
      RtcEngine rtcEngine = createAgoraRtcEngine();
      await rtcEngine.initialize(RtcEngineContext(
        appId: 'app_id',
        areaCode: AreaCode.areaCodeGlob.value(),
      ));
      await rtcEngine.setParameters('{"rtc.enable_debug_log": true}');
      final mediaEngine = rtcEngine.getMediaEngine();

      final onMediaPlayerVideoFrameCompleter = Completer<bool>();
      final theVideoFrameObserver = VideoFrameObserver(
        onMediaPlayerVideoFrame: (VideoFrame videoFrame, int mediaPlayerId) {
          onMediaPlayerVideoFrameCompleter.complete(true);
        },
      );

      mediaEngine.registerVideoFrameObserver(
        theVideoFrameObserver,
      );

// Delay 500 milliseconds to ensure the registerVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      {
        const VideoPixelFormat videoFrameType =
            VideoPixelFormat.videoPixelDefault;
        const VideoFrameMetaInfo? videoFrameMetaInfo = null;
        const int videoFrameWidth = 10;
        const int videoFrameHeight = 10;
        const int videoFrameYStride = 10;
        const int videoFrameUStride = 10;
        const int videoFrameVStride = 10;
        Uint8List videoFrameYBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameUBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameVBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameRotation = 10;
        const int videoFrameRenderTimeMs = 10;
        const int videoFrameAvsyncType = 10;
        Uint8List videoFrameMetadataBuffer =
            Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameMetadataSize = 10;
        const int videoFrameTextureId = 10;
        const List<double> videoFrameMatrix = [];
        Uint8List videoFrameAlphaBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFramePixelBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        final VideoFrame videoFrame = VideoFrame(
          type: videoFrameType,
          width: videoFrameWidth,
          height: videoFrameHeight,
          yStride: videoFrameYStride,
          uStride: videoFrameUStride,
          vStride: videoFrameVStride,
          yBuffer: videoFrameYBuffer,
          uBuffer: videoFrameUBuffer,
          vBuffer: videoFrameVBuffer,
          rotation: videoFrameRotation,
          renderTimeMs: videoFrameRenderTimeMs,
          avsyncType: videoFrameAvsyncType,
          metadataBuffer: videoFrameMetadataBuffer,
          metadataSize: videoFrameMetadataSize,
          textureId: videoFrameTextureId,
          matrix: videoFrameMatrix,
          alphaBuffer: videoFrameAlphaBuffer,
          pixelBuffer: videoFramePixelBuffer,
          metaInfo: videoFrameMetaInfo,
        );
        const int mediaPlayerId = 10;

        final eventJson = {
          'videoFrame': videoFrame.toJson(),
          'mediaPlayerId': mediaPlayerId,
        };

        final eventIds =
            eventIdsMapping['VideoFrameObserver_onMediaPlayerVideoFrame'] ?? [];
        for (final event in eventIds) {
          final ret = irisTester().fireEvent(event, params: eventJson);
          // Delay 200 milliseconds to ensure the callback is called.
          await Future.delayed(const Duration(milliseconds: 200));
          // TODO(littlegnal): Most of callbacks on web are not implemented, we're temporarily skip these callbacks at this time.
          if (kIsWeb && ret) {
            if (!onMediaPlayerVideoFrameCompleter.isCompleted) {
              onMediaPlayerVideoFrameCompleter.complete(true);
            }
          }
        }
      }

      final eventCalled = await onMediaPlayerVideoFrameCompleter.future;
      expect(eventCalled, isTrue);

      {
        mediaEngine.unregisterVideoFrameObserver(
          theVideoFrameObserver,
        );
      }
// Delay 500 milliseconds to ensure the unregisterVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      await rtcEngine.release();
    },
    timeout: const Timeout(Duration(minutes: 2)),
  );

  testWidgets(
    'VideoFrameObserver.onRenderVideoFrame',
    (WidgetTester tester) async {
      RtcEngine rtcEngine = createAgoraRtcEngine();
      await rtcEngine.initialize(RtcEngineContext(
        appId: 'app_id',
        areaCode: AreaCode.areaCodeGlob.value(),
      ));
      await rtcEngine.setParameters('{"rtc.enable_debug_log": true}');
      final mediaEngine = rtcEngine.getMediaEngine();

      final onRenderVideoFrameCompleter = Completer<bool>();
      final theVideoFrameObserver = VideoFrameObserver(
        onRenderVideoFrame:
            (String channelId, int remoteUid, VideoFrame videoFrame) {
          onRenderVideoFrameCompleter.complete(true);
        },
      );

      mediaEngine.registerVideoFrameObserver(
        theVideoFrameObserver,
      );

// Delay 500 milliseconds to ensure the registerVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      {
        const String channelId = "hello";
        const int remoteUid = 10;
        const VideoPixelFormat videoFrameType =
            VideoPixelFormat.videoPixelDefault;
        const VideoFrameMetaInfo? videoFrameMetaInfo = null;
        const int videoFrameWidth = 10;
        const int videoFrameHeight = 10;
        const int videoFrameYStride = 10;
        const int videoFrameUStride = 10;
        const int videoFrameVStride = 10;
        Uint8List videoFrameYBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameUBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameVBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameRotation = 10;
        const int videoFrameRenderTimeMs = 10;
        const int videoFrameAvsyncType = 10;
        Uint8List videoFrameMetadataBuffer =
            Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameMetadataSize = 10;
        const int videoFrameTextureId = 10;
        const List<double> videoFrameMatrix = [];
        Uint8List videoFrameAlphaBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFramePixelBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        final VideoFrame videoFrame = VideoFrame(
          type: videoFrameType,
          width: videoFrameWidth,
          height: videoFrameHeight,
          yStride: videoFrameYStride,
          uStride: videoFrameUStride,
          vStride: videoFrameVStride,
          yBuffer: videoFrameYBuffer,
          uBuffer: videoFrameUBuffer,
          vBuffer: videoFrameVBuffer,
          rotation: videoFrameRotation,
          renderTimeMs: videoFrameRenderTimeMs,
          avsyncType: videoFrameAvsyncType,
          metadataBuffer: videoFrameMetadataBuffer,
          metadataSize: videoFrameMetadataSize,
          textureId: videoFrameTextureId,
          matrix: videoFrameMatrix,
          alphaBuffer: videoFrameAlphaBuffer,
          pixelBuffer: videoFramePixelBuffer,
          metaInfo: videoFrameMetaInfo,
        );

        final eventJson = {
          'channelId': channelId,
          'remoteUid': remoteUid,
          'videoFrame': videoFrame.toJson(),
        };

        final eventIds =
            eventIdsMapping['VideoFrameObserver_onRenderVideoFrame'] ?? [];
        for (final event in eventIds) {
          final ret = irisTester().fireEvent(event, params: eventJson);
          // Delay 200 milliseconds to ensure the callback is called.
          await Future.delayed(const Duration(milliseconds: 200));
          // TODO(littlegnal): Most of callbacks on web are not implemented, we're temporarily skip these callbacks at this time.
          if (kIsWeb && ret) {
            if (!onRenderVideoFrameCompleter.isCompleted) {
              onRenderVideoFrameCompleter.complete(true);
            }
          }
        }
      }

      final eventCalled = await onRenderVideoFrameCompleter.future;
      expect(eventCalled, isTrue);

      {
        mediaEngine.unregisterVideoFrameObserver(
          theVideoFrameObserver,
        );
      }
// Delay 500 milliseconds to ensure the unregisterVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      await rtcEngine.release();
    },
    timeout: const Timeout(Duration(minutes: 2)),
  );

  testWidgets(
    'VideoFrameObserver.onTranscodedVideoFrame',
    (WidgetTester tester) async {
      RtcEngine rtcEngine = createAgoraRtcEngine();
      await rtcEngine.initialize(RtcEngineContext(
        appId: 'app_id',
        areaCode: AreaCode.areaCodeGlob.value(),
      ));
      await rtcEngine.setParameters('{"rtc.enable_debug_log": true}');
      final mediaEngine = rtcEngine.getMediaEngine();

      final onTranscodedVideoFrameCompleter = Completer<bool>();
      final theVideoFrameObserver = VideoFrameObserver(
        onTranscodedVideoFrame: (VideoFrame videoFrame) {
          onTranscodedVideoFrameCompleter.complete(true);
        },
      );

      mediaEngine.registerVideoFrameObserver(
        theVideoFrameObserver,
      );

// Delay 500 milliseconds to ensure the registerVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      {
        const VideoPixelFormat videoFrameType =
            VideoPixelFormat.videoPixelDefault;
        const VideoFrameMetaInfo? videoFrameMetaInfo = null;
        const int videoFrameWidth = 10;
        const int videoFrameHeight = 10;
        const int videoFrameYStride = 10;
        const int videoFrameUStride = 10;
        const int videoFrameVStride = 10;
        Uint8List videoFrameYBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameUBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFrameVBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameRotation = 10;
        const int videoFrameRenderTimeMs = 10;
        const int videoFrameAvsyncType = 10;
        Uint8List videoFrameMetadataBuffer =
            Uint8List.fromList([1, 2, 3, 4, 5]);
        const int videoFrameMetadataSize = 10;
        const int videoFrameTextureId = 10;
        const List<double> videoFrameMatrix = [];
        Uint8List videoFrameAlphaBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        Uint8List videoFramePixelBuffer = Uint8List.fromList([1, 2, 3, 4, 5]);
        final VideoFrame videoFrame = VideoFrame(
          type: videoFrameType,
          width: videoFrameWidth,
          height: videoFrameHeight,
          yStride: videoFrameYStride,
          uStride: videoFrameUStride,
          vStride: videoFrameVStride,
          yBuffer: videoFrameYBuffer,
          uBuffer: videoFrameUBuffer,
          vBuffer: videoFrameVBuffer,
          rotation: videoFrameRotation,
          renderTimeMs: videoFrameRenderTimeMs,
          avsyncType: videoFrameAvsyncType,
          metadataBuffer: videoFrameMetadataBuffer,
          metadataSize: videoFrameMetadataSize,
          textureId: videoFrameTextureId,
          matrix: videoFrameMatrix,
          alphaBuffer: videoFrameAlphaBuffer,
          pixelBuffer: videoFramePixelBuffer,
          metaInfo: videoFrameMetaInfo,
        );

        final eventJson = {
          'videoFrame': videoFrame.toJson(),
        };

        final eventIds =
            eventIdsMapping['VideoFrameObserver_onTranscodedVideoFrame'] ?? [];
        for (final event in eventIds) {
          final ret = irisTester().fireEvent(event, params: eventJson);
          // Delay 200 milliseconds to ensure the callback is called.
          await Future.delayed(const Duration(milliseconds: 200));
          // TODO(littlegnal): Most of callbacks on web are not implemented, we're temporarily skip these callbacks at this time.
          if (kIsWeb && ret) {
            if (!onTranscodedVideoFrameCompleter.isCompleted) {
              onTranscodedVideoFrameCompleter.complete(true);
            }
          }
        }
      }

      final eventCalled = await onTranscodedVideoFrameCompleter.future;
      expect(eventCalled, isTrue);

      {
        mediaEngine.unregisterVideoFrameObserver(
          theVideoFrameObserver,
        );
      }
// Delay 500 milliseconds to ensure the unregisterVideoFrameObserver call completed.
      await Future.delayed(const Duration(milliseconds: 500));

      await rtcEngine.release();
    },
    timeout: const Timeout(Duration(minutes: 2)),
  );
}
